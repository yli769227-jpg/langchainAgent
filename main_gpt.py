"""
LangChain Agent Backend - FastAPI
æ‰‹åŠ¨å·¥å…·è°ƒç”¨å¾ªç¯å®ç°ï¼Œå…¼å®¹ç¬¬ä¸‰æ–¹/ä¸­è½¬ OpenAI æ ¼å¼æ¥å£
ä¸ä¾èµ– LangGraphï¼Œé¿å… model_dump / tool_calls æ ¼å¼å…¼å®¹é—®é¢˜
"""
import math
import datetime
import json
from typing import Optional
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import asyncio
from openai import OpenAI

app = FastAPI(title="LangChain Agent API", version="1.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== Tools å®ç° ====================

def calculator(expression: str) -> str:
    try:
        allowed_names = {k: v for k, v in math.__dict__.items() if not k.startswith("__")}
        allowed_names.update({"abs": abs, "round": round, "pow": pow})
        result = eval(expression, {"__builtins__": {}}, allowed_names)
        return f"è®¡ç®—ç»“æœ: {expression} = {result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯: {str(e)}"


def get_current_time(timezone: str = "Asia/Shanghai") -> str:
    now = datetime.datetime.now()
    return (
        f"å½“å‰æ—¶é—´ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰: {now.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n"
        f"æ˜ŸæœŸ: {['å‘¨ä¸€','å‘¨äºŒ','å‘¨ä¸‰','å‘¨å››','å‘¨äº”','å‘¨å…­','å‘¨æ—¥'][now.weekday()]}\n"
        f"ä»Šå¹´ç¬¬ {now.timetuple().tm_yday} å¤©"
    )


def text_analyzer(text: str) -> str:
    lines = text.split('\n')
    words = text.split()
    chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
    return (
        f"ğŸ“Š æ–‡æœ¬åˆ†æç»“æœ:\n"
        f"  - æ€»å­—ç¬¦æ•°: {len(text)}\n"
        f"  - ä¸­æ–‡å­—ç¬¦æ•°: {chinese_chars}\n"
        f"  - è‹±æ–‡å•è¯æ•°: {len(words)}\n"
        f"  - è¡Œæ•°: {len(lines)}\n"
        f"  - æ®µè½æ•°: {len([l for l in lines if l.strip()])}"
    )


def unit_converter(value: float, from_unit: str, to_unit: str) -> str:
    conversions = {
        ("m", "km"): 0.001,         ("km", "m"): 1000,
        ("m", "mile"): 0.000621371, ("mile", "m"): 1609.34,
        ("m", "ft"): 3.28084,       ("ft", "m"): 0.3048,
        ("m", "cm"): 100,           ("cm", "m"): 0.01,
        ("m", "mm"): 1000,          ("mm", "m"): 0.001,
        ("km", "mile"): 0.621371,   ("mile", "km"): 1.60934,
        ("cm", "mm"): 10,           ("mm", "cm"): 0.1,
        ("kg", "lb"): 2.20462,      ("lb", "kg"): 0.453592,
        ("kg", "g"): 1000,          ("g", "kg"): 0.001,
        ("kg", "oz"): 35.274,       ("oz", "kg"): 0.0283495,
        ("g", "oz"): 0.035274,      ("oz", "g"): 28.3495,
    }
    key = (from_unit.lower(), to_unit.lower())
    f, t = from_unit.lower(), to_unit.lower()
    if f == "celsius" and t == "fahrenheit":
        result = value * 9/5 + 32
    elif f == "fahrenheit" and t == "celsius":
        result = (value - 32) * 5/9
    elif f == "celsius" and t == "kelvin":
        result = value + 273.15
    elif f == "kelvin" and t == "celsius":
        result = value - 273.15
    elif key in conversions:
        result = value * conversions[key]
    else:
        return f"ä¸æ”¯æŒ {from_unit} åˆ° {to_unit} çš„æ¢ç®—"
    return f"{value} {from_unit} = {result:.4f} {to_unit}"


def word_counter(text: str, target_word: str) -> str:
    count = text.lower().count(target_word.lower())
    return f"è¯è¯­ '{target_word}' åœ¨æ–‡æœ¬ä¸­å‡ºç°äº† {count} æ¬¡"


# å·¥å…·åˆ†å‘è¡¨
TOOL_FUNCTIONS = {
    "calculator": calculator,
    "get_current_time": get_current_time,
    "text_analyzer": text_analyzer,
    "unit_converter": unit_converter,
    "word_counter": word_counter,
}

# ==================== OpenAI tools æ ¼å¼å®šä¹‰ ====================

TOOLS_SCHEMA = [
    {
        "type": "function",
        "function": {
            "name": "calculator",
            "description": "æ‰§è¡Œæ•°å­¦è®¡ç®—ã€‚æ”¯æŒåŸºæœ¬å››åˆ™è¿ç®—ã€å¹‚è¿ç®—ã€ä¸‰è§’å‡½æ•°ã€å¯¹æ•°ç­‰ã€‚ç¤ºä¾‹: '2 + 3 * 4', 'sqrt(16)'",
            "parameters": {
                "type": "object",
                "properties": {
                    "expression": {"type": "string", "description": "æ•°å­¦è¡¨è¾¾å¼å­—ç¬¦ä¸²"}
                },
                "required": ["expression"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_current_time",
            "description": "è·å–å½“å‰æ—¥æœŸå’Œæ—¶é—´ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰",
            "parameters": {
                "type": "object",
                "properties": {
                    "timezone": {"type": "string", "description": "æ—¶åŒºï¼Œé»˜è®¤ Asia/Shanghai"}
                },
                "required": []
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "text_analyzer",
            "description": "åˆ†ææ–‡æœ¬ç»Ÿè®¡ä¿¡æ¯ï¼šå­—ç¬¦æ•°ã€è¯æ•°ã€è¡Œæ•°ã€ä¸­æ–‡å­—ç¬¦æ•°ç­‰",
            "parameters": {
                "type": "object",
                "properties": {
                    "text": {"type": "string", "description": "è¦åˆ†æçš„æ–‡æœ¬"}
                },
                "required": ["text"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "unit_converter",
            "description": "å•ä½æ¢ç®—ã€‚æ”¯æŒé•¿åº¦(m,km,mile,ft,cm,mm)ã€é‡é‡(kg,lb,g,oz)ã€æ¸©åº¦(celsius,fahrenheit,kelvin)",
            "parameters": {
                "type": "object",
                "properties": {
                    "value": {"type": "number", "description": "è¦æ¢ç®—çš„æ•°å€¼"},
                    "from_unit": {"type": "string", "description": "åŸå•ä½"},
                    "to_unit": {"type": "string", "description": "ç›®æ ‡å•ä½"}
                },
                "required": ["value", "from_unit", "to_unit"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "word_counter",
            "description": "åœ¨æ–‡æœ¬ä¸­ç»Ÿè®¡ç‰¹å®šè¯è¯­å‡ºç°çš„æ¬¡æ•°ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰",
            "parameters": {
                "type": "object",
                "properties": {
                    "text": {"type": "string", "description": "è¦æœç´¢çš„æ–‡æœ¬"},
                    "target_word": {"type": "string", "description": "è¦ç»Ÿè®¡çš„è¯è¯­"}
                },
                "required": ["text", "target_word"]
            }
        }
    }
]

SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå…·å¤‡å¤šç§å®ç”¨å·¥å…·èƒ½åŠ›ã€‚ä½ å¯ä»¥å¸®åŠ©ç”¨æˆ·è¿›è¡Œï¼š
- æ•°å­¦è®¡ç®—ï¼ˆä½¿ç”¨ calculator å·¥å…·ï¼‰
- æŸ¥è¯¢å½“å‰æ—¶é—´ï¼ˆä½¿ç”¨ get_current_time å·¥å…·ï¼‰
- æ–‡æœ¬åˆ†æï¼ˆä½¿ç”¨ text_analyzer å·¥å…·ï¼‰
- å•ä½æ¢ç®—ï¼ˆä½¿ç”¨ unit_converter å·¥å…·ï¼‰
- è¯è¯­ç»Ÿè®¡ï¼ˆä½¿ç”¨ word_counter å·¥å…·ï¼‰

è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œçµæ´»ä½¿ç”¨å·¥å…·ï¼Œç»™å‡ºå‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ã€‚
å›ç­”æ—¶è¯·ç”¨ä¸­æ–‡ï¼Œå¹¶ä¿æŒå‹å¥½ã€ä¸“ä¸šçš„è¯­æ°”ã€‚
å¦‚æœä¸éœ€è¦å·¥å…·ï¼Œç›´æ¥å›ç­”å³å¯ã€‚"""

# å…¨å±€ä¼šè¯å†å²
session_histories: dict[str, list] = {}


def run_agent(api_key: str, base_url: str, model_name: str, messages: list) -> tuple[str, list]:
    """
    æ‰‹åŠ¨å·¥å…·è°ƒç”¨å¾ªç¯ï¼Œå®Œå…¨åŸºäºåŸç”Ÿ OpenAI SDKã€‚
    å…¼å®¹æ‰€æœ‰æ”¯æŒ OpenAI æ ¼å¼çš„ä¸­è½¬æœåŠ¡ã€‚
    è¿”å› (æœ€ç»ˆå›å¤æ–‡æœ¬, å·¥å…·è°ƒç”¨æ­¥éª¤åˆ—è¡¨)
    """
    client = OpenAI(api_key=api_key, base_url=base_url)
    steps = []
    # æœ€å¤šå¾ªç¯ 10 æ¬¡ï¼Œé˜²æ­¢æ­»å¾ªç¯
    for _ in range(10):
        response = client.chat.completions.create(
            model=model_name,
            messages=messages,
            tools=TOOLS_SCHEMA,
            tool_choice="auto",
        )

        msg = response.choices[0].message

        # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›
        if not msg.tool_calls:
            return msg.content, steps

        # æœ‰å·¥å…·è°ƒç”¨ï¼Œé€ä¸ªæ‰§è¡Œ
        # æŠŠ assistant æ¶ˆæ¯åŠ å…¥å†å²
        messages.append({
            "role": "assistant",
            "content": msg.content or "",
            "tool_calls": [
                {
                    "id": tc.id,
                    "type": "function",
                    "function": {
                        "name": tc.function.name,
                        "arguments": tc.function.arguments,
                    }
                }
                for tc in msg.tool_calls
            ]
        })

        for tc in msg.tool_calls:
            func_name = tc.function.name
            try:
                func_args = json.loads(tc.function.arguments)
            except Exception:
                func_args = {}

            # æ‰§è¡Œå·¥å…·
            if func_name in TOOL_FUNCTIONS:
                tool_result = TOOL_FUNCTIONS[func_name](**func_args)
            else:
                tool_result = f"æœªçŸ¥å·¥å…·: {func_name}"

            steps.append({
                "tool": func_name,
                "input": func_args,
                "output": tool_result,
            })

            # æŠŠå·¥å…·ç»“æœåŠ å…¥å†å²
            messages.append({
                "role": "tool",
                "tool_call_id": tc.id,
                "content": tool_result,
            })

    # è¶…è¿‡æœ€å¤§å¾ªç¯æ¬¡æ•°ï¼Œå¼ºåˆ¶è¿”å›
    return "æŠ±æ­‰ï¼Œå¤„ç†è¿‡ç¨‹ä¸­é‡åˆ°äº†é—®é¢˜ï¼Œè¯·é‡è¯•ã€‚", steps


# ==================== API Models ====================

class ChatRequest(BaseModel):
    message: str
    session_id: str = "default"
    api_key: str
    base_url: str = "https://api.penguinsaichat.dpdns.org/v1"
    model_name: str = "claude-sonnet-4-6"


# ==================== API Routes ====================

@app.get("/health")
async def health():
    return {"status": "ok", "message": "Agent is running"}


@app.get("/tools")
async def get_tools():
    return {
        "tools": [
            {
                "name": t["function"]["name"],
                "description": t["function"]["description"]
            }
            for t in TOOLS_SCHEMA
        ]
    }


@app.post("/chat")
async def chat(req: ChatRequest):
    try:
        history = session_histories.get(req.session_id, [])

        # æ„é€ å®Œæ•´æ¶ˆæ¯åˆ—è¡¨ï¼ˆSystemMessage + å†å² + å½“å‰é—®é¢˜ï¼‰
        messages = (
            [{"role": "system", "content": SYSTEM_PROMPT}]
            + history
            + [{"role": "user", "content": req.message}]
        )

        response_text, steps = await asyncio.to_thread(
            run_agent, req.api_key, req.base_url, req.model_name, messages
        )

        # æ›´æ–°å†å²ï¼Œä¿ç•™æœ€è¿‘ 20 æ¡
        history.append({"role": "user", "content": req.message})
        history.append({"role": "assistant", "content": response_text})
        session_histories[req.session_id] = history[-20:]

        return {
            "response": response_text,
            "steps": steps,
            "session_id": req.session_id,
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/chat/{session_id}")
async def clear_history(session_id: str):
    if session_id in session_histories:
        del session_histories[session_id]
    return {"message": f"Session {session_id} cleared"}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=False)
